{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subarudad/gh-collab/blob/main/github_code_understanding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkCrLE2lLwLh"
      },
      "outputs": [],
      "source": [
        "# github repo instruction text to code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai chromadb"
      ],
      "metadata": {
        "id": "fYZq7B77Ly1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "uGGaOBORLy3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install deeplake\n",
        "\n",
        "# https://www.activeloop.ai/resources/lang-chain-gpt-4-for-code-understanding-twitter-algorithm/\n",
        "\n",
        "# https://python.langchain.com/docs/use_cases/code/code-analysis-deeplake\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"ACTIVELOOP_TOKEN\"] = getpass.getpass(\"Activeloop Token:\")\n",
        "\n",
        "# os.environ['ACTIVELOOP_TOKEN']='ACTIVELOOP_TOKEN'\n"
      ],
      "metadata": {
        "id": "JuY5EAvoF8Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fqin1Wy2WCgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain, OpenAI, Cohere, HuggingFaceHub\n"
      ],
      "metadata": {
        "id": "VmTX741fNfrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "root_dir = './the-algorithm'\n",
        "\n",
        "# scrape any files from directory\n",
        "\n",
        "docs = []\n",
        "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "    for file in filenames:\n",
        "        try:\n",
        "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
        "            docs.extend(loader.load_and_split())\n",
        "        except Exception as e:\n",
        "            pass\n"
      ],
      "metadata": {
        "id": "m-OqOJaoXWyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "TEXT_SPLITTER_CHUNK_PARAMS = {\n",
        "    \"chunk_size\": 2000,\n",
        "    \"chunk_overlap\": 0,\n",
        "    \"length_function\": len,\n",
        "}\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(**TEXT_SPLITTER_CHUNK_PARAMS)\n",
        "texts = text_splitter.split_documents(docs)\n"
      ],
      "metadata": {
        "id": "YltqZqmmMp2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/chroma"
      ],
      "metadata": {
        "id": "6Pea7fEVSPiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "text_vdb = Chroma.from_texts(texts, embeddings, metadatas=metadatas, dataset_path=dataset_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "K3CxyOJaSPka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.vectorstores import DeepLake\n",
        "\n",
        "# db = DeepLake.from_documents(\n",
        "#     texts, embeddings, dataset_path=f\"hub://{DEEPLAKE_ACCOUNT_NAME}/langchain-code\"\n",
        "# )\n",
        "# db\n",
        "\n",
        "# replace with your username from app.activeloop.ai\n",
        "# db = DeepLake(dataset_path=f\"hub://{username}/twitter-algorithm\", embedding_function=embeddings)\n",
        "# db.add_documents(texts)\n"
      ],
      "metadata": {
        "id": "eYVS5anVXQAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'What are the first programs he tried writing?'\n",
        "query_docs = text_vdb.similarity_search(query = prompt)\n",
        "print(query_docs[0].page_content)\n",
        "\n"
      ],
      "metadata": {
        "id": "PqTBuB2VS5tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "retriever = text_vdb.as_retriever()\n",
        "retriever.search_kwargs[\"exec_option\"] = \"compute_engine\"\n",
        "retriever.search_kwargs['distance_metric'] = 'cos'\n",
        "retriever.search_kwargs['fetch_k'] = 100\n",
        "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
        "retriever.search_kwargs['k'] = 10\n",
        "\n",
        "# retriever = db.as_retriever(search_type=\"mmr\")\n",
        "\n",
        "retriever.get_relevant_documents(query)[0]\n"
      ],
      "metadata": {
        "id": "083R-P8pSPmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.llms import OpenAIChat\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qna = RetrievalQA.from_chain_type(llm = OpenAIChat(model = 'gpt-3.5-turbo'),\n",
        "                                  chain_type = 'stuff', retriever = retriever)\n",
        "\n",
        "qna.run(prompt)\n"
      ],
      "metadata": {
        "id": "QKA4-yeBSPof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"What is the class hierarchy?\",\n",
        "    # \"What classes are derived from the Chain class?\",\n",
        "    # \"What classes and functions in the ./langchain/utilities/ forlder are not covered by unit tests?\",\n",
        "    # \"What one improvement do you propose in code in relation to the class herarchy for the Chain class?\",\n",
        "]\n",
        "chat_history = []\n",
        "\n",
        "for question in questions:\n",
        "    result = qna({\"question\": question, \"chat_history\": chat_history})\n",
        "    chat_history.append((question, result[\"answer\"]))\n",
        "    print(f\"-> **Question**: {question} \\n\")\n",
        "    print(f\"**Answer**: {result['answer']} \\n\")"
      ],
      "metadata": {
        "id": "yw3sLss6SPql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YATUbXigMp5W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}